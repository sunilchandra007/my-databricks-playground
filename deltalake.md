# ðŸ’¾ Delta Lake

**Delta Lake** is an open-source **storage layer** on top of data lake that works seamlessly with **Apache Spark**.

---

## ðŸš€ Why Delta Lake?

Delta Lake enhances traditional data lakes by adding:

- âœ… **ACID Transactions** â€“ Ensures data consistency even with concurrent reads/writes.
- ðŸ”„ **Schema Enforcement & Evolution** â€“ Prevents bad data and supports flexible schemas.
- ðŸ•’ **Time Travel** â€“ Query previous versions of your data for audits or debugging.
- âš¡ **Performance Optimizations** â€“ Faster reads/writes with indexing and caching.

---

## ðŸ”— Delta Lake + Apache Spark

Delta Lake is built to work with **Apache Spark**. You use familiar Spark APIs to read, write, and transform data stored in Delta format.

### ðŸ§ª Example: Reading and Writing Delta Tables

```python
# Read from a Delta table
df = spark.read.format("delta").load("/mnt/delta/sales")

# Transform the data
df_filtered = df.filter(df["region"] == "Asia")

# Write back to a Delta table
df_filtered.write.format("delta").mode("overwrite").save("/mnt/delta/sales_asia")
```

---

## ðŸ“š Learn More

Explore the official documentation:  
ðŸ‘‰ [Delta Lake](https://www.youtube.com/watch?v=HQvAl0Bwpu8)
